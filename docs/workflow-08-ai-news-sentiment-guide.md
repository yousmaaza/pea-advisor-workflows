# ü§ñ Workflow 08 - AI News Sentiment Analyzer (Llama3.2)

## üìã Vue d'ensemble

Analyse automatique du sentiment des actualit√©s financi√®res en utilisant **Llama3.2** (mod√®le open source de Meta) via Ollama.

**Avantages** :
- ‚úÖ **100% gratuit** (pas de co√ªts API)
- ‚úÖ **Open source** (Llama3.2 par Meta)
- ‚úÖ **Local** (h√©berg√© dans Docker)
- ‚úÖ **Confidentiel** (donn√©es restent sur votre serveur)
- ‚úÖ **Illimit√©** (pas de rate limits)

---

## üéØ Objectif

Analyser le sentiment (positif/n√©gatif/neutre) et l'impact potentiel de chaque actualit√© sur le cours des actions pour aider √† la prise de d√©cision d'investissement.

---

## üèóÔ∏è Architecture

### Nodes du Workflow (8 nodes - LangChain)

```
1. D√©clencheur Quotidien 20h (Schedule Trigger)
   ‚Üì
2. R√©cup√©rer news non analys√©es (PostgreSQL)
   ‚Üì
3. Pr√©parer Prompt + Context (Set)
   ‚Üì
4. AI Agent (LLM Chain) ‚Üê connect√© √† ‚Üí Ollama Chat Model (Llama3.2)
   ‚Üì
5. Parser R√©sultat Python (Code Python)
   ‚Üì
6. Filtrer succ√®s (Filter)
   ‚Üì
7. Mettre √† jour news (PostgreSQL)
   ‚Üì
8. Log succ√®s (PostgreSQL)
```

**Architecture LangChain** :
- **Ollama Chat Model** : Node de mod√®le de langage (se connecte via `ai_languageModel`)
- **AI Agent** : LLM Chain qui re√ßoit le prompt et utilise le mod√®le Ollama
- Connexion sp√©ciale : Ollama Chat Model ‚Üí (ai_languageModel) ‚Üí AI Agent

---

## üîß Configuration Technique

### 1. Ollama Configuration

Ollama est d√©j√† install√© dans votre environnement Docker :

```yaml
# docker-compose.yml
services:
  ollama-cpu:  # ou ollama-gpu si GPU disponible
    image: ollama/ollama:latest
    container_name: ollama
    networks: ['demo']
    ports:
      - 11434:11434
```

**URL interne** : `http://ollama:11434`
**Mod√®le** : `llama3.2` (auto-pulled au d√©marrage)

### 2. Node "Pr√©parer Prompt + Context" (Set)

**Type** : `n8n-nodes-base.set`

Ce node pr√©pare trois variables pour l'AI Agent :
- `prompt_text` : Le prompt complet avec les donn√©es de la news
- `news_id` : L'ID de la news pour mise √† jour ult√©rieure
- `stock_id` : L'ID de l'action associ√©e

### 3. Node "Ollama Chat Model" (LangChain)

**Type** : `@n8n/n8n-nodes-langchain.lmChatOllama`

Configuration :
```json
{
  "model": "llama3.2",
  "options": {
    "temperature": 0.3,
    "maxTokens": 500
  }
}
```

**Credentials** : `ollamaApi` (pointe vers `http://ollama:11434`)

### 4. Node "AI Agent" (LLM Chain)

**Type** : `@n8n/n8n-nodes-langchain.chainLlm`

Configuration :
```json
{
  "text": "={{ $json.prompt_text }}"
}
```

**Connexion** : Re√ßoit le mod√®le via connexion `ai_languageModel` depuis "Ollama Chat Model"

### 5. Prompt Engineering

Le prompt demande √† Llama de retourner un JSON structur√© :

```
Tu es un analyste financier expert. Analyse le sentiment de cet article
financier et retourne UNIQUEMENT un JSON valide sans texte suppl√©mentaire.

Titre: [...]
Description: [...]
Contenu: [...]

Retourne UNIQUEMENT ce JSON :
{
  "sentiment_score": [nombre entre -10 et +10],
  "sentiment_label": "negative" ou "neutral" ou "positive",
  "impact_score": [nombre entre 0 et 10],
  "ai_summary": "r√©sum√© en 2-3 phrases maximum",
  "ai_key_points": ["point 1", "point 2", "point 3"]
}
```

**Param√®tres** :
- `temperature: 0.3` ‚Üí R√©ponses plus d√©terministes (moins cr√©atives)
- `num_predict: 500` ‚Üí Maximum 500 tokens de r√©ponse

---

## üìä Donn√©es Analys√©es

### Input (SELECT)

R√©cup√®re les news non analys√©es des 7 derniers jours :

```sql
SELECT
  id,
  stock_id,
  title,
  description,
  content,
  url,
  source,
  published_at
FROM news
WHERE sentiment_score IS NULL
  AND created_at >= CURRENT_DATE - INTERVAL '7 days'
ORDER BY published_at DESC
LIMIT 50;
```

### Output (UPDATE)

Met √† jour la table `news` avec :

| Champ            | Type          | Description                           | Exemple      |
|------------------|---------------|---------------------------------------|--------------|
| `sentiment_score`| DECIMAL(5,2)  | Score -10 (tr√®s n√©gatif) √† +10 (tr√®s positif) | -3.50        |
| `sentiment_label`| VARCHAR(20)   | negative / neutral / positive         | "positive"   |
| `impact_score`   | DECIMAL(5,2)  | Impact estim√© 0 (nul) √† 10 (majeur)  | 7.20         |
| `ai_summary`     | TEXT          | R√©sum√© en 2-3 phrases                 | "..."        |
| `ai_key_points`  | JSONB         | Points cl√©s extraits                  | ["..."]      |

---

## üêç Code Python - Parser R√©sultat

Le code Python nettoie et parse la r√©ponse de Llama3.2 :

### √âtapes du parsing

1. **Nettoyage markdown** :
   ```python
   # Enlever ```json ... ```
   if '```json' in cleaned_response:
       match = re.search(r'```json\s*({.*?})\s*```', cleaned_response, re.DOTALL)
   ```

2. **Extraction JSON** :
   ```python
   # Extraire le JSON s'il est entour√© de texte
   json_match = re.search(r'{[^{}]*(?:{[^{}]*}[^{}]*)*}', cleaned_response, re.DOTALL)
   ```

3. **Validation des valeurs** :
   ```python
   # Clamp sentiment_score entre -10 et +10
   sentiment_score = max(-10, min(10, sentiment_score))

   # Clamp impact_score entre 0 et 10
   impact_score = max(0, min(10, impact_score))

   # Valider sentiment_label
   if sentiment_label not in ['negative', 'neutral', 'positive']:
       if sentiment_score < -2:
           sentiment_label = 'negative'
       elif sentiment_score > 2:
           sentiment_label = 'positive'
       else:
           sentiment_label = 'neutral'
   ```

4. **Gestion d'erreur** :
   - En cas d'erreur de parsing, retourne des valeurs neutres
   - Log l'erreur avec les 300 premiers caract√®res de la r√©ponse

---

## ‚è∞ Schedule

**Trigger** : Tous les jours √† 20h00 (Europe/Paris)
**Fr√©quence** : 1 fois par jour
**Traitement** : Maximum 50 news par ex√©cution

**Pourquoi 20h00** ?
- Apr√®s la collecte des news (Workflow 02 : toutes les 4h)
- Apr√®s la fermeture des march√©s europ√©ens
- Avant le rapport quotidien

---

## üîç Exemples de R√©sultats

### Exemple 1 : R√©sultat positif

**Article** : "LVMH annonce des r√©sultats record pour Q4 2025"

**Analyse Llama3.2** :
```json
{
  "sentiment_score": 8.5,
  "sentiment_label": "positive",
  "impact_score": 9.0,
  "ai_summary": "LVMH annonce des r√©sultats trimestriels exceptionnels, d√©passant les attentes du march√©. Forte croissance en Asie et augmentation des marges.",
  "ai_key_points": [
    "R√©sultats Q4 record",
    "Forte croissance Asie (+15%)",
    "Augmentation des marges"
  ]
}
```

### Exemple 2 : R√©sultat n√©gatif

**Article** : "TotalEnergies fait face √† des sanctions environnementales"

**Analyse Llama3.2** :
```json
{
  "sentiment_score": -6.2,
  "sentiment_label": "negative",
  "impact_score": 7.5,
  "ai_summary": "TotalEnergies pourrait faire face √† des amendes importantes suite √† des violations environnementales. Impact potentiel sur la rentabilit√© √† court terme.",
  "ai_key_points": [
    "Sanctions environnementales majeures",
    "Amendes potentielles",
    "Impact sur la rentabilit√©"
  ]
}
```

### Exemple 3 : R√©sultat neutre

**Article** : "Airbus participe au salon a√©ronautique de Farnborough"

**Analyse Llama3.2** :
```json
{
  "sentiment_score": 0.5,
  "sentiment_label": "neutral",
  "impact_score": 2.0,
  "ai_summary": "Airbus participe au salon a√©ronautique de Farnborough pour pr√©senter ses derniers produits. √âv√©nement annuel standard de l'industrie.",
  "ai_key_points": [
    "Participation au salon de Farnborough",
    "Pr√©sentation de produits",
    "√âv√©nement r√©current de l'industrie"
  ]
}
```

---

## üìà Utilisation des R√©sultats

### 1. Filtrage des opportunit√©s

```sql
-- News tr√®s positives sur actions suivies
SELECT s.ticker, n.title, n.sentiment_score, n.impact_score
FROM news n
JOIN stocks s ON s.id = n.stock_id
WHERE n.sentiment_score > 5
  AND n.impact_score > 7
  AND s.is_pea_eligible = true
ORDER BY n.sentiment_score DESC, n.impact_score DESC
LIMIT 10;
```

### 2. Alertes sur sentiment n√©gatif

```sql
-- News tr√®s n√©gatives n√©cessitant attention
SELECT s.ticker, n.title, n.sentiment_score
FROM news n
JOIN stocks s ON s.id = n.stock_id
JOIN portfolio p ON p.stock_id = s.id
WHERE n.sentiment_score < -5
  AND p.is_open = true
ORDER BY n.published_at DESC;
```

### 3. Agr√©gation par action

```sql
-- Sentiment moyen par action (7 derniers jours)
SELECT
  s.ticker,
  COUNT(*) as nb_articles,
  ROUND(AVG(n.sentiment_score), 2) as avg_sentiment,
  ROUND(AVG(n.impact_score), 2) as avg_impact
FROM news n
JOIN stocks s ON s.id = n.stock_id
WHERE n.published_at >= CURRENT_DATE - INTERVAL '7 days'
  AND n.sentiment_score IS NOT NULL
GROUP BY s.ticker
HAVING COUNT(*) >= 3
ORDER BY avg_sentiment DESC;
```

---

## üêõ Troubleshooting

### Probl√®me 1 : Ollama ne r√©pond pas

**Erreur** : `Connection refused to http://ollama:11434`

**Solution** :
```bash
# V√©rifier que Ollama est d√©marr√©
docker ps | grep ollama

# Red√©marrer Ollama
docker restart ollama

# V√©rifier les logs
docker logs ollama
```

### Probl√®me 2 : JSON invalide de Llama

**Sympt√¥me** : Toutes les news ont `success: false`

**Solution** :
- V√©rifier les logs syst√®me : `SELECT * FROM system_logs WHERE workflow_name = 'ai-news-sentiment-analyzer' AND success = false`
- Examiner `raw_response` pour voir ce que Llama retourne
- Ajuster le prompt pour √™tre plus explicite

### Probl√®me 3 : Llama3.2 pas install√©

**Erreur** : `model 'llama3.2' not found`

**Solution** :
```bash
# Se connecter au container Ollama
docker exec -it ollama bash

# Pull le mod√®le manuellement
ollama pull llama3.2

# V√©rifier les mod√®les install√©s
ollama list
```

### Probl√®me 4 : Timeout (60s d√©pass√©)

**Sympt√¥me** : Certaines news ne sont pas analys√©es

**Cause** : Llama prend trop de temps pour r√©pondre

**Solution** :
- Augmenter le timeout dans le HTTP Request node : `"timeout": 120000` (2 minutes)
- R√©duire la longueur du contenu : `.substring(0, 500)` au lieu de 1000

---

## ‚ö° Performance

### Temps d'ex√©cution

- **1 news** : ~2-5 secondes (selon CPU/GPU)
- **50 news** : ~2-5 minutes
- **D√©pend de** : Puissance CPU/GPU, longueur des articles

### Optimisations possibles

1. **GPU** : Utiliser `ollama-gpu` au lieu de `ollama-cpu` (10x plus rapide)
2. **Batch** : Analyser plusieurs news en une seule requ√™te (√† impl√©menter)
3. **Cache** : Ne pas r√©analyser les news d√©j√† trait√©es (d√©j√† impl√©ment√©)
4. **Mod√®le l√©ger** : Utiliser `llama3.2:1b` au lieu de la version compl√®te

---

## üîê Avantages vs LLM Commerciaux

| Crit√®re             | Llama3.2 (Ollama) | OpenAI GPT-4 | Claude     |
|---------------------|-------------------|--------------|------------|
| **Co√ªt**            | ‚úÖ Gratuit        | üí∞ $0.01/req | üí∞ $0.015/req |
| **Limite**          | ‚úÖ Illimit√©       | ‚ö†Ô∏è Rate limits | ‚ö†Ô∏è Rate limits |
| **Confidentialit√©** | ‚úÖ Local          | ‚ùå Cloud     | ‚ùå Cloud   |
| **Latence**         | ‚úÖ Rapide (local) | ‚ö†Ô∏è R√©seau    | ‚ö†Ô∏è R√©seau  |
| **Qualit√©**         | ‚≠ê‚≠ê‚≠ê Bon        | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent |

**Estimation co√ªts mensuel** :
- Llama3.2 : **0‚Ç¨** (gratuit, illimit√©)
- OpenAI : **~15‚Ç¨** (50 news/jour √ó 30 jours √ó $0.01)
- Claude : **~22‚Ç¨** (50 news/jour √ó 30 jours √ó $0.015)

---

## üöÄ Prochaines Am√©liorations

1. **Mod√®le sp√©cialis√©** : Fine-tuner Llama3.2 sur des news financi√®res fran√ßaises
2. **Analyse multi-langue** : D√©tecter et analyser news en anglais
3. **Extraction d'entit√©s** : Identifier automatiquement entreprises, produits, personnes mentionn√©es
4. **Comparaison historique** : Comparer le sentiment actuel vs historique
5. **Score composite** : Agr√©ger sentiment news + indicateurs techniques

---

## üìö Ressources

- **Ollama Documentation** : https://ollama.ai/
- **Llama3.2 Model Card** : https://huggingface.co/meta-llama/Llama-3.2
- **n8n Ollama Integration** : https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/
- **Financial Sentiment Analysis** : https://arxiv.org/abs/2107.08055

---

**Derni√®re mise √† jour** : 3 janvier 2026
**Version** : 1.0
**Auteur** : PEA Advisor Team
