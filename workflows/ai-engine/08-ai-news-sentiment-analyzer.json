{
  "name": "08-ai-news-sentiment-analyzer",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "cronExpression",
              "expression": "0 20 * * *"
            }
          ]
        },
        "timezone": "Europe/Paris"
      },
      "id": "schedule-trigger",
      "name": "Déclencheur Quotidien 20h",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.1,
      "position": [240, 300]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT \n  id,\n  stock_id,\n  title,\n  description,\n  content,\n  url,\n  source,\n  published_at\nFROM news \nWHERE sentiment_score IS NULL \n  AND created_at >= CURRENT_DATE - INTERVAL '7 days'\nORDER BY published_at DESC\nLIMIT 50;",
        "options": {}
      },
      "id": "get-news-to-analyze",
      "name": "Récupérer news non analysées",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [460, 300],
      "credentials": {
        "postgres": {
          "id": "1",
          "name": "PostgreSQL PEA Advisor"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const newsData = $input.item.json;\n\n// Construire le prompt\nconst prompt = `Tu es un analyste financier expert. Analyse le sentiment de cet article financier et retourne UNIQUEMENT un JSON valide sans texte supplémentaire ni markdown.\n\nTitre: ${newsData.title}\n\nDescription: ${newsData.description || 'N/A'}\n\nContenu: ${(newsData.content || 'N/A').substring(0, 1000)}\n\nRetourne UNIQUEMENT ce JSON (sans \\`\\`\\`json, sans explication) :\n{\n  \"sentiment_score\": [nombre entre -10 et +10],\n  \"sentiment_label\": \"negative\" ou \"neutral\" ou \"positive\",\n  \"impact_score\": [nombre entre 0 et 10],\n  \"ai_summary\": \"résumé en 2-3 phrases maximum\",\n  \"ai_key_points\": [\"point 1\", \"point 2\", \"point 3\"]\n}`;\n\nreturn {\n  json: {\n    prompt_text: prompt,\n    news_id: newsData.id,\n    stock_id: newsData.stock_id\n  }\n};"
      },
      "id": "prepare-prompt",
      "name": "Préparer Prompt + Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 300]
    },
    {
      "parameters": {
        "model": "llama3.2",
        "options": {
          "temperature": 0.3,
          "maxTokens": 500
        }
      },
      "id": "ollama-chat-model",
      "name": "Ollama Chat Model (Llama3.2)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [900, 480],
      "credentials": {
        "ollamaApi": {
          "id": "ollama-local",
          "name": "Ollama Local"
        }
      }
    },
    {
      "parameters": {
        "text": "={{ $json.prompt_text }}",
        "options": {}
      },
      "id": "basic-llm-chain",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.3,
      "position": [900, 180]
    },
    {
      "parameters": {
        "mode": "combine",
        "combinationMode": "mergeByPosition",
        "options": {}
      },
      "id": "merge-data",
      "name": "Combiner données",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [1120, 300]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "language": "python",
        "pythonCode": "import json\nimport re\nfrom zoneinfo import ZoneInfo\nfrom datetime import datetime\n\n# Timezone Europe/Paris\nparis_tz = ZoneInfo('Europe/Paris')\n\n# Récupérer la réponse de l'AI Agent et le contexte\nai_response = _item['json'].get('response', '') or _item['json'].get('output', '') or _item['json'].get('text', '')\nnews_id = _item['json'].get('news_id')\nstock_id = _item['json'].get('stock_id')\n\ntry:\n    # Nettoyer la réponse (enlever markdown si présent)\n    cleaned_response = ai_response.strip()\n    \n    # Enlever les balises markdown ```json ... ``` si présentes\n    if '```json' in cleaned_response:\n        match = re.search(r'```json\\s*({.*?})\\s*```', cleaned_response, re.DOTALL)\n        if match:\n            cleaned_response = match.group(1)\n    elif '```' in cleaned_response:\n        match = re.search(r'```\\s*({.*?})\\s*```', cleaned_response, re.DOTALL)\n        if match:\n            cleaned_response = match.group(1)\n    \n    # Extraire le JSON s'il est entouré de texte\n    json_match = re.search(r'{[^{}]*(?:{[^{}]*}[^{}]*)*}', cleaned_response, re.DOTALL)\n    if json_match:\n        cleaned_response = json_match.group(0)\n    \n    # Parser le JSON\n    sentiment_data = json.loads(cleaned_response)\n    \n    # Valider et normaliser les données\n    sentiment_score = float(sentiment_data.get('sentiment_score', 0))\n    sentiment_score = max(-10, min(10, sentiment_score))  # Clamp entre -10 et +10\n    \n    impact_score = float(sentiment_data.get('impact_score', 0))\n    impact_score = max(0, min(10, impact_score))  # Clamp entre 0 et 10\n    \n    sentiment_label = str(sentiment_data.get('sentiment_label', 'neutral')).lower()\n    if sentiment_label not in ['negative', 'neutral', 'positive']:\n        # Déduire le label du score si invalide\n        if sentiment_score < -2:\n            sentiment_label = 'negative'\n        elif sentiment_score > 2:\n            sentiment_label = 'positive'\n        else:\n            sentiment_label = 'neutral'\n    \n    ai_summary = sentiment_data.get('ai_summary', '')\n    ai_key_points = sentiment_data.get('ai_key_points', [])\n    \n    # Si ai_key_points n'est pas une liste, le convertir\n    if not isinstance(ai_key_points, list):\n        ai_key_points = [str(ai_key_points)]\n    \n    # Limiter la taille\n    ai_summary_clean = (ai_summary[:500] if ai_summary else None)\n    ai_key_points_clean = ai_key_points[:5] if ai_key_points else []\n    \n    # Échapper les apostrophes pour PostgreSQL\n    if ai_summary_clean:\n        ai_summary_clean = ai_summary_clean.replace(\"'\", \"''\")\n    \n    return {\n        'json': {\n            'news_id': news_id,\n            'stock_id': stock_id,\n            'sentiment_score': round(sentiment_score, 2),\n            'sentiment_label': sentiment_label,\n            'impact_score': round(impact_score, 2),\n            'ai_summary': ai_summary_clean,\n            'ai_key_points': json.dumps(ai_key_points_clean, ensure_ascii=False),\n            'analyzed_at': datetime.now(paris_tz).isoformat(),\n            'success': True\n        }\n    }\n\nexcept Exception as error:\n    # En cas d'erreur, retourner des valeurs neutres avec log d'erreur\n    return {\n        'json': {\n            'news_id': news_id or 0,\n            'stock_id': stock_id or 0,\n            'sentiment_score': 0,\n            'sentiment_label': 'neutral',\n            'impact_score': 0,\n            'ai_summary': None,\n            'ai_key_points': None,\n            'success': False,\n            'error': str(error),\n            'raw_response': ai_response[:300] if ai_response else 'No response'\n        }\n    }"
      },
      "id": "parse-sentiment",
      "name": "Parser Résultat Python",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1340, 300]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "leftValue": "={{ $json.success }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "filter-success",
      "name": "Filtrer succès",
      "type": "n8n-nodes-base.filter",
      "typeVersion": 2,
      "position": [1560, 300]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=UPDATE news \nSET \n  sentiment_score = {{ $json.sentiment_score }},\n  sentiment_label = '{{ $json.sentiment_label }}',\n  impact_score = {{ $json.impact_score }},\n  ai_summary = {{ $json.ai_summary ? \"'\" + $json.ai_summary + \"'\" : \"NULL\" }},\n  ai_key_points = {{ $json.ai_key_points ? \"'\" + $json.ai_key_points + \"'::jsonb\" : \"NULL\" }}\nWHERE id = {{ $json.news_id }}\nRETURNING id, stock_id, sentiment_score, sentiment_label;",
        "options": {}
      },
      "id": "update-news",
      "name": "Mettre à jour news",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [1780, 300],
      "credentials": {
        "postgres": {
          "id": "1",
          "name": "PostgreSQL PEA Advisor"
        }
      }
    },
    {
      "parameters": {
        "operation": "insert",
        "schema": "public",
        "table": "system_logs",
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "workflow_name": "ai-news-sentiment-analyzer",
            "level": "info",
            "message": "={{ 'Sentiment analysé pour news ' + $json.id + ' (score: ' + $json.sentiment_score + ', label: ' + $json.sentiment_label + ')' }}",
            "details": "={{ { news_id: $json.id, stock_id: $json.stock_id, sentiment_score: $json.sentiment_score, sentiment_label: $json.sentiment_label } }}",
            "created_at": "={{ $now }}"
          }
        },
        "options": {}
      },
      "id": "log-success",
      "name": "Log succès",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [2000, 300],
      "credentials": {
        "postgres": {
          "id": "1",
          "name": "PostgreSQL PEA Advisor"
        }
      }
    }
  ],
  "connections": {
    "Déclencheur Quotidien 20h": {
      "main": [[{"node": "Récupérer news non analysées", "type": "main", "index": 0}]]
    },
    "Récupérer news non analysées": {
      "main": [[{"node": "Préparer Prompt + Context", "type": "main", "index": 0}]]
    },
    "Préparer Prompt + Context": {
      "main": [
        [
          {"node": "AI Agent", "type": "main", "index": 0},
          {"node": "Combiner données", "type": "main", "index": 0}
        ]
      ]
    },
    "Ollama Chat Model (Llama3.2)": {
      "ai_languageModel": [[{"node": "AI Agent", "type": "ai_languageModel", "index": 0}]]
    },
    "AI Agent": {
      "main": [[{"node": "Combiner données", "type": "main", "index": 1}]]
    },
    "Combiner données": {
      "main": [[{"node": "Parser Résultat Python", "type": "main", "index": 0}]]
    },
    "Parser Résultat Python": {
      "main": [[{"node": "Filtrer succès", "type": "main", "index": 0}]]
    },
    "Filtrer succès": {
      "main": [[{"node": "Mettre à jour news", "type": "main", "index": 0}]]
    },
    "Mettre à jour news": {
      "main": [[{"node": "Log succès", "type": "main", "index": 0}]]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner"
  },
  "staticData": null,
  "tags": [
    {"id": "1", "name": "PEA Advisor"},
    {"id": "7", "name": "AI Analysis"},
    {"id": "4", "name": "News"}
  ],
  "triggerCount": 1,
  "updatedAt": "2026-01-03T22:30:00.000Z",
  "versionId": "2.2"
}
